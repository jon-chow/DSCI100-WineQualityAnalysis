{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predicting Wine Quality Through Classification and Regression**\n",
    "#### DSCI 100 Winter T2 Group 006-042"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consumer selection on wine has been heavily dependent on quality certifications for purchasing decisions and producers have been doing the same for pricing (Cortez et al., 2009). The certification for wine quality is a tedious process, requiring wine experts (connoisseurs) to sample the taste and smell of the wine to determine its quality (Cortez et al., 2009). However, there are biases when conducting these sensory taste tests due to personal preferences of the experts and the complex nature of the human taste bud (Smith and Margolskee, 2001).\n",
    "\n",
    "We would like to know whether it is possible to obtain an accurate model to predict wine quality based on its chemical properties, ultimately replacing human sensory evaluators.\n",
    "For this purpose, we use the KNN classification model over a data set containing the chemical properties and quality of 1599 different red wines.\n",
    "\n",
    "The data set is collected in 2009 by Cortez et al. and has the following 12 variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attribute (units):\n",
    "- Fixed acidity ($g/dm^3$)\n",
    "- Volatile acidity ($g/dm^3$)\n",
    "- Citric acid ($g/dm^3$)\n",
    "- Residual sugar ($g/dm^3$)\n",
    "- Chlorides ($g/dm^3$)\n",
    "- Free sulfur dioxide ($mg/dm^3$)\n",
    "- Total sulfur dioxide ($mg/dm^3$)\n",
    "- Density ($g/cm^3$)\n",
    "- pH\n",
    "- Sulphates ($g/dm^3$)\n",
    "- Alcohol ($vol.\\%$)\n",
    "- Quality (from 0 to 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality variable is determined from the range 0-10 based on the evaluations of 3 human assessors.\n",
    "\n",
    "We will not be using all the given variables for quality prediction, as we find some of the variables correlated, and some not related to the quality. The way we choose the variables is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Exploratory Data Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading libraries\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "library(gridExtra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 1,599\n",
      "Columns: 12\n",
      "$ fixed.acidity        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 7.4, 7.8, 7.8, 11.2, 7.4, 7.4, 7.9, 7.3, 7.8, 7.…\n",
      "$ volatile.acidity     \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0.700, 0.880, 0.760, 0.280, 0.700, 0.660, 0.600,…\n",
      "$ citric.acid          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0.00, 0.00, 0.04, 0.56, 0.00, 0.00, 0.06, 0.00, …\n",
      "$ residual.sugar       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 1.9, 2.6, 2.3, 1.9, 1.9, 1.8, 1.6, 1.2, 2.0, 6.1…\n",
      "$ chlorides            \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0.076, 0.098, 0.092, 0.075, 0.076, 0.075, 0.069,…\n",
      "$ free.sulfur.dioxide  \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 11, 25, 15, 17, 11, 13, 15, 15, 9, 17, 15, 17, 1…\n",
      "$ total.sulfur.dioxide \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 34, 67, 54, 60, 34, 40, 59, 21, 18, 102, 65, 102…\n",
      "$ density              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0.9978, 0.9968, 0.9970, 0.9980, 0.9978, 0.9978, …\n",
      "$ pH                   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 3.51, 3.20, 3.26, 3.16, 3.51, 3.51, 3.30, 3.39, …\n",
      "$ sulphates            \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0.56, 0.68, 0.65, 0.58, 0.56, 0.56, 0.46, 0.47, …\n",
      "$ alcohol              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 9.4, 9.8, 9.8, 9.8, 9.4, 9.4, 9.4, 10.0, 9.5, 10…\n",
      "$ quality              \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 5, 5, 5, 6, 5, 5, 5, 7, 7, 5, 5, 5, 5, 5, 5, 5, …\n"
     ]
    }
   ],
   "source": [
    "# reading data\n",
    "url <- \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "destination <- \"data/red_wine_quality.csv\"\n",
    "download.file(url, destination)\n",
    "\n",
    "data <- read.csv(destination, head = TRUE, sep = \";\")\n",
    "glimpse(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 1599 × 12</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>_____________</th><th scope=col>________________</th><th scope=col>___________</th><th scope=col>______________</th><th scope=col>_________</th><th scope=col>___________________</th><th scope=col>____________________</th><th scope=col>_______</th><th scope=col>__</th><th scope=col>_________</th><th scope=col>_______</th><th scope=col>_______</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 7.4</td><td>0.700</td><td>0.00</td><td>1.9</td><td>0.076</td><td>11</td><td> 34</td><td>0.9978</td><td>3.51</td><td>0.56</td><td> 9.4</td><td>5</td></tr>\n",
       "\t<tr><td> 7.8</td><td>0.880</td><td>0.00</td><td>2.6</td><td>0.098</td><td>25</td><td> 67</td><td>0.9968</td><td>3.20</td><td>0.68</td><td> 9.8</td><td>5</td></tr>\n",
       "\t<tr><td> 7.8</td><td>0.760</td><td>0.04</td><td>2.3</td><td>0.092</td><td>15</td><td> 54</td><td>0.9970</td><td>3.26</td><td>0.65</td><td> 9.8</td><td>5</td></tr>\n",
       "\t<tr><td>11.2</td><td>0.280</td><td>0.56</td><td>1.9</td><td>0.075</td><td>17</td><td> 60</td><td>0.9980</td><td>3.16</td><td>0.58</td><td> 9.8</td><td>6</td></tr>\n",
       "\t<tr><td> 7.4</td><td>0.700</td><td>0.00</td><td>1.9</td><td>0.076</td><td>11</td><td> 34</td><td>0.9978</td><td>3.51</td><td>0.56</td><td> 9.4</td><td>5</td></tr>\n",
       "\t<tr><td> 7.4</td><td>0.660</td><td>0.00</td><td>1.8</td><td>0.075</td><td>13</td><td> 40</td><td>0.9978</td><td>3.51</td><td>0.56</td><td> 9.4</td><td>5</td></tr>\n",
       "\t<tr><td> 7.9</td><td>0.600</td><td>0.06</td><td>1.6</td><td>0.069</td><td>15</td><td> 59</td><td>0.9964</td><td>3.30</td><td>0.46</td><td> 9.4</td><td>5</td></tr>\n",
       "\t<tr><td> 7.3</td><td>0.650</td><td>0.00</td><td>1.2</td><td>0.065</td><td>15</td><td> 21</td><td>0.9946</td><td>3.39</td><td>0.47</td><td>10.0</td><td>7</td></tr>\n",
       "\t<tr><td> 7.8</td><td>0.580</td><td>0.02</td><td>2.0</td><td>0.073</td><td> 9</td><td> 18</td><td>0.9968</td><td>3.36</td><td>0.57</td><td> 9.5</td><td>7</td></tr>\n",
       "\t<tr><td> 7.5</td><td>0.500</td><td>0.36</td><td>6.1</td><td>0.071</td><td>17</td><td>102</td><td>0.9978</td><td>3.35</td><td>0.80</td><td>10.5</td><td>5</td></tr>\n",
       "\t<tr><td> 6.7</td><td>0.580</td><td>0.08</td><td>1.8</td><td>0.097</td><td>15</td><td> 65</td><td>0.9959</td><td>3.28</td><td>0.54</td><td> 9.2</td><td>5</td></tr>\n",
       "\t<tr><td> 7.5</td><td>0.500</td><td>0.36</td><td>6.1</td><td>0.071</td><td>17</td><td>102</td><td>0.9978</td><td>3.35</td><td>0.80</td><td>10.5</td><td>5</td></tr>\n",
       "\t<tr><td> 5.6</td><td>0.615</td><td>0.00</td><td>1.6</td><td>0.089</td><td>16</td><td> 59</td><td>0.9943</td><td>3.58</td><td>0.52</td><td> 9.9</td><td>5</td></tr>\n",
       "\t<tr><td> 7.8</td><td>0.610</td><td>0.29</td><td>1.6</td><td>0.114</td><td> 9</td><td> 29</td><td>0.9974</td><td>3.26</td><td>1.56</td><td> 9.1</td><td>5</td></tr>\n",
       "\t<tr><td> 8.9</td><td>0.620</td><td>0.18</td><td>3.8</td><td>0.176</td><td>52</td><td>145</td><td>0.9986</td><td>3.16</td><td>0.88</td><td> 9.2</td><td>5</td></tr>\n",
       "\t<tr><td> 8.9</td><td>0.620</td><td>0.19</td><td>3.9</td><td>0.170</td><td>51</td><td>148</td><td>0.9986</td><td>3.17</td><td>0.93</td><td> 9.2</td><td>5</td></tr>\n",
       "\t<tr><td> 8.5</td><td>0.280</td><td>0.56</td><td>1.8</td><td>0.092</td><td>35</td><td>103</td><td>0.9969</td><td>3.30</td><td>0.75</td><td>10.5</td><td>7</td></tr>\n",
       "\t<tr><td> 8.1</td><td>0.560</td><td>0.28</td><td>1.7</td><td>0.368</td><td>16</td><td> 56</td><td>0.9968</td><td>3.11</td><td>1.28</td><td> 9.3</td><td>5</td></tr>\n",
       "\t<tr><td> 7.4</td><td>0.590</td><td>0.08</td><td>4.4</td><td>0.086</td><td> 6</td><td> 29</td><td>0.9974</td><td>3.38</td><td>0.50</td><td> 9.0</td><td>4</td></tr>\n",
       "\t<tr><td> 7.9</td><td>0.320</td><td>0.51</td><td>1.8</td><td>0.341</td><td>17</td><td> 56</td><td>0.9969</td><td>3.04</td><td>1.08</td><td> 9.2</td><td>6</td></tr>\n",
       "\t<tr><td> 8.9</td><td>0.220</td><td>0.48</td><td>1.8</td><td>0.077</td><td>29</td><td> 60</td><td>0.9968</td><td>3.39</td><td>0.53</td><td> 9.4</td><td>6</td></tr>\n",
       "\t<tr><td> 7.6</td><td>0.390</td><td>0.31</td><td>2.3</td><td>0.082</td><td>23</td><td> 71</td><td>0.9982</td><td>3.52</td><td>0.65</td><td> 9.7</td><td>5</td></tr>\n",
       "\t<tr><td> 7.9</td><td>0.430</td><td>0.21</td><td>1.6</td><td>0.106</td><td>10</td><td> 37</td><td>0.9966</td><td>3.17</td><td>0.91</td><td> 9.5</td><td>5</td></tr>\n",
       "\t<tr><td> 8.5</td><td>0.490</td><td>0.11</td><td>2.3</td><td>0.084</td><td> 9</td><td> 67</td><td>0.9968</td><td>3.17</td><td>0.53</td><td> 9.4</td><td>5</td></tr>\n",
       "\t<tr><td> 6.9</td><td>0.400</td><td>0.14</td><td>2.4</td><td>0.085</td><td>21</td><td> 40</td><td>0.9968</td><td>3.43</td><td>0.63</td><td> 9.7</td><td>6</td></tr>\n",
       "\t<tr><td> 6.3</td><td>0.390</td><td>0.16</td><td>1.4</td><td>0.080</td><td>11</td><td> 23</td><td>0.9955</td><td>3.34</td><td>0.56</td><td> 9.3</td><td>5</td></tr>\n",
       "\t<tr><td> 7.6</td><td>0.410</td><td>0.24</td><td>1.8</td><td>0.080</td><td> 4</td><td> 11</td><td>0.9962</td><td>3.28</td><td>0.59</td><td> 9.5</td><td>5</td></tr>\n",
       "\t<tr><td> 7.9</td><td>0.430</td><td>0.21</td><td>1.6</td><td>0.106</td><td>10</td><td> 37</td><td>0.9966</td><td>3.17</td><td>0.91</td><td> 9.5</td><td>5</td></tr>\n",
       "\t<tr><td> 7.1</td><td>0.710</td><td>0.00</td><td>1.9</td><td>0.080</td><td>14</td><td> 35</td><td>0.9972</td><td>3.47</td><td>0.55</td><td> 9.4</td><td>5</td></tr>\n",
       "\t<tr><td> 7.8</td><td>0.645</td><td>0.00</td><td>2.0</td><td>0.082</td><td> 8</td><td> 16</td><td>0.9964</td><td>3.38</td><td>0.59</td><td> 9.8</td><td>6</td></tr>\n",
       "\t<tr><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td><td>⋮</td></tr>\n",
       "\t<tr><td>6.2</td><td>0.510</td><td>0.14</td><td> 1.9</td><td>0.056</td><td>15</td><td> 34</td><td>0.99396</td><td>3.48</td><td>0.57</td><td>11.5</td><td>6</td></tr>\n",
       "\t<tr><td>6.4</td><td>0.360</td><td>0.53</td><td> 2.2</td><td>0.230</td><td>19</td><td> 35</td><td>0.99340</td><td>3.37</td><td>0.93</td><td>12.4</td><td>6</td></tr>\n",
       "\t<tr><td>6.4</td><td>0.380</td><td>0.14</td><td> 2.2</td><td>0.038</td><td>15</td><td> 25</td><td>0.99514</td><td>3.44</td><td>0.65</td><td>11.1</td><td>6</td></tr>\n",
       "\t<tr><td>7.3</td><td>0.690</td><td>0.32</td><td> 2.2</td><td>0.069</td><td>35</td><td>104</td><td>0.99632</td><td>3.33</td><td>0.51</td><td> 9.5</td><td>5</td></tr>\n",
       "\t<tr><td>6.0</td><td>0.580</td><td>0.20</td><td> 2.4</td><td>0.075</td><td>15</td><td> 50</td><td>0.99467</td><td>3.58</td><td>0.67</td><td>12.5</td><td>6</td></tr>\n",
       "\t<tr><td>5.6</td><td>0.310</td><td>0.78</td><td>13.9</td><td>0.074</td><td>23</td><td> 92</td><td>0.99677</td><td>3.39</td><td>0.48</td><td>10.5</td><td>6</td></tr>\n",
       "\t<tr><td>7.5</td><td>0.520</td><td>0.40</td><td> 2.2</td><td>0.060</td><td>12</td><td> 20</td><td>0.99474</td><td>3.26</td><td>0.64</td><td>11.8</td><td>6</td></tr>\n",
       "\t<tr><td>8.0</td><td>0.300</td><td>0.63</td><td> 1.6</td><td>0.081</td><td>16</td><td> 29</td><td>0.99588</td><td>3.30</td><td>0.78</td><td>10.8</td><td>6</td></tr>\n",
       "\t<tr><td>6.2</td><td>0.700</td><td>0.15</td><td> 5.1</td><td>0.076</td><td>13</td><td> 27</td><td>0.99622</td><td>3.54</td><td>0.60</td><td>11.9</td><td>6</td></tr>\n",
       "\t<tr><td>6.8</td><td>0.670</td><td>0.15</td><td> 1.8</td><td>0.118</td><td>13</td><td> 20</td><td>0.99540</td><td>3.42</td><td>0.67</td><td>11.3</td><td>6</td></tr>\n",
       "\t<tr><td>6.2</td><td>0.560</td><td>0.09</td><td> 1.7</td><td>0.053</td><td>24</td><td> 32</td><td>0.99402</td><td>3.54</td><td>0.60</td><td>11.3</td><td>5</td></tr>\n",
       "\t<tr><td>7.4</td><td>0.350</td><td>0.33</td><td> 2.4</td><td>0.068</td><td> 9</td><td> 26</td><td>0.99470</td><td>3.36</td><td>0.60</td><td>11.9</td><td>6</td></tr>\n",
       "\t<tr><td>6.2</td><td>0.560</td><td>0.09</td><td> 1.7</td><td>0.053</td><td>24</td><td> 32</td><td>0.99402</td><td>3.54</td><td>0.60</td><td>11.3</td><td>5</td></tr>\n",
       "\t<tr><td>6.1</td><td>0.715</td><td>0.10</td><td> 2.6</td><td>0.053</td><td>13</td><td> 27</td><td>0.99362</td><td>3.57</td><td>0.50</td><td>11.9</td><td>5</td></tr>\n",
       "\t<tr><td>6.2</td><td>0.460</td><td>0.29</td><td> 2.1</td><td>0.074</td><td>32</td><td> 98</td><td>0.99578</td><td>3.33</td><td>0.62</td><td> 9.8</td><td>5</td></tr>\n",
       "\t<tr><td>6.7</td><td>0.320</td><td>0.44</td><td> 2.4</td><td>0.061</td><td>24</td><td> 34</td><td>0.99484</td><td>3.29</td><td>0.80</td><td>11.6</td><td>7</td></tr>\n",
       "\t<tr><td>7.2</td><td>0.390</td><td>0.44</td><td> 2.6</td><td>0.066</td><td>22</td><td> 48</td><td>0.99494</td><td>3.30</td><td>0.84</td><td>11.5</td><td>6</td></tr>\n",
       "\t<tr><td>7.5</td><td>0.310</td><td>0.41</td><td> 2.4</td><td>0.065</td><td>34</td><td> 60</td><td>0.99492</td><td>3.34</td><td>0.85</td><td>11.4</td><td>6</td></tr>\n",
       "\t<tr><td>5.8</td><td>0.610</td><td>0.11</td><td> 1.8</td><td>0.066</td><td>18</td><td> 28</td><td>0.99483</td><td>3.55</td><td>0.66</td><td>10.9</td><td>6</td></tr>\n",
       "\t<tr><td>7.2</td><td>0.660</td><td>0.33</td><td> 2.5</td><td>0.068</td><td>34</td><td>102</td><td>0.99414</td><td>3.27</td><td>0.78</td><td>12.8</td><td>6</td></tr>\n",
       "\t<tr><td>6.6</td><td>0.725</td><td>0.20</td><td> 7.8</td><td>0.073</td><td>29</td><td> 79</td><td>0.99770</td><td>3.29</td><td>0.54</td><td> 9.2</td><td>5</td></tr>\n",
       "\t<tr><td>6.3</td><td>0.550</td><td>0.15</td><td> 1.8</td><td>0.077</td><td>26</td><td> 35</td><td>0.99314</td><td>3.32</td><td>0.82</td><td>11.6</td><td>6</td></tr>\n",
       "\t<tr><td>5.4</td><td>0.740</td><td>0.09</td><td> 1.7</td><td>0.089</td><td>16</td><td> 26</td><td>0.99402</td><td>3.67</td><td>0.56</td><td>11.6</td><td>6</td></tr>\n",
       "\t<tr><td>6.3</td><td>0.510</td><td>0.13</td><td> 2.3</td><td>0.076</td><td>29</td><td> 40</td><td>0.99574</td><td>3.42</td><td>0.75</td><td>11.0</td><td>6</td></tr>\n",
       "\t<tr><td>6.8</td><td>0.620</td><td>0.08</td><td> 1.9</td><td>0.068</td><td>28</td><td> 38</td><td>0.99651</td><td>3.42</td><td>0.82</td><td> 9.5</td><td>6</td></tr>\n",
       "\t<tr><td>6.2</td><td>0.600</td><td>0.08</td><td> 2.0</td><td>0.090</td><td>32</td><td> 44</td><td>0.99490</td><td>3.45</td><td>0.58</td><td>10.5</td><td>5</td></tr>\n",
       "\t<tr><td>5.9</td><td>0.550</td><td>0.10</td><td> 2.2</td><td>0.062</td><td>39</td><td> 51</td><td>0.99512</td><td>3.52</td><td>0.76</td><td>11.2</td><td>6</td></tr>\n",
       "\t<tr><td>6.3</td><td>0.510</td><td>0.13</td><td> 2.3</td><td>0.076</td><td>29</td><td> 40</td><td>0.99574</td><td>3.42</td><td>0.75</td><td>11.0</td><td>6</td></tr>\n",
       "\t<tr><td>5.9</td><td>0.645</td><td>0.12</td><td> 2.0</td><td>0.075</td><td>32</td><td> 44</td><td>0.99547</td><td>3.57</td><td>0.71</td><td>10.2</td><td>5</td></tr>\n",
       "\t<tr><td>6.0</td><td>0.310</td><td>0.47</td><td> 3.6</td><td>0.067</td><td>18</td><td> 42</td><td>0.99549</td><td>3.39</td><td>0.66</td><td>11.0</td><td>6</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1599 × 12\n",
       "\\begin{tabular}{llllllllllll}\n",
       " \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ & \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ & \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ & \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ & \\_\\_\\_\\_\\_\\_\\_\\_\\_ & \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ & \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_ & \\_\\_\\_\\_\\_\\_\\_ & \\_\\_ & \\_\\_\\_\\_\\_\\_\\_\\_\\_ & \\_\\_\\_\\_\\_\\_\\_ & \\_\\_\\_\\_\\_\\_\\_\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <int>\\\\\n",
       "\\hline\n",
       "\t  7.4 & 0.700 & 0.00 & 1.9 & 0.076 & 11 &  34 & 0.9978 & 3.51 & 0.56 &  9.4 & 5\\\\\n",
       "\t  7.8 & 0.880 & 0.00 & 2.6 & 0.098 & 25 &  67 & 0.9968 & 3.20 & 0.68 &  9.8 & 5\\\\\n",
       "\t  7.8 & 0.760 & 0.04 & 2.3 & 0.092 & 15 &  54 & 0.9970 & 3.26 & 0.65 &  9.8 & 5\\\\\n",
       "\t 11.2 & 0.280 & 0.56 & 1.9 & 0.075 & 17 &  60 & 0.9980 & 3.16 & 0.58 &  9.8 & 6\\\\\n",
       "\t  7.4 & 0.700 & 0.00 & 1.9 & 0.076 & 11 &  34 & 0.9978 & 3.51 & 0.56 &  9.4 & 5\\\\\n",
       "\t  7.4 & 0.660 & 0.00 & 1.8 & 0.075 & 13 &  40 & 0.9978 & 3.51 & 0.56 &  9.4 & 5\\\\\n",
       "\t  7.9 & 0.600 & 0.06 & 1.6 & 0.069 & 15 &  59 & 0.9964 & 3.30 & 0.46 &  9.4 & 5\\\\\n",
       "\t  7.3 & 0.650 & 0.00 & 1.2 & 0.065 & 15 &  21 & 0.9946 & 3.39 & 0.47 & 10.0 & 7\\\\\n",
       "\t  7.8 & 0.580 & 0.02 & 2.0 & 0.073 &  9 &  18 & 0.9968 & 3.36 & 0.57 &  9.5 & 7\\\\\n",
       "\t  7.5 & 0.500 & 0.36 & 6.1 & 0.071 & 17 & 102 & 0.9978 & 3.35 & 0.80 & 10.5 & 5\\\\\n",
       "\t  6.7 & 0.580 & 0.08 & 1.8 & 0.097 & 15 &  65 & 0.9959 & 3.28 & 0.54 &  9.2 & 5\\\\\n",
       "\t  7.5 & 0.500 & 0.36 & 6.1 & 0.071 & 17 & 102 & 0.9978 & 3.35 & 0.80 & 10.5 & 5\\\\\n",
       "\t  5.6 & 0.615 & 0.00 & 1.6 & 0.089 & 16 &  59 & 0.9943 & 3.58 & 0.52 &  9.9 & 5\\\\\n",
       "\t  7.8 & 0.610 & 0.29 & 1.6 & 0.114 &  9 &  29 & 0.9974 & 3.26 & 1.56 &  9.1 & 5\\\\\n",
       "\t  8.9 & 0.620 & 0.18 & 3.8 & 0.176 & 52 & 145 & 0.9986 & 3.16 & 0.88 &  9.2 & 5\\\\\n",
       "\t  8.9 & 0.620 & 0.19 & 3.9 & 0.170 & 51 & 148 & 0.9986 & 3.17 & 0.93 &  9.2 & 5\\\\\n",
       "\t  8.5 & 0.280 & 0.56 & 1.8 & 0.092 & 35 & 103 & 0.9969 & 3.30 & 0.75 & 10.5 & 7\\\\\n",
       "\t  8.1 & 0.560 & 0.28 & 1.7 & 0.368 & 16 &  56 & 0.9968 & 3.11 & 1.28 &  9.3 & 5\\\\\n",
       "\t  7.4 & 0.590 & 0.08 & 4.4 & 0.086 &  6 &  29 & 0.9974 & 3.38 & 0.50 &  9.0 & 4\\\\\n",
       "\t  7.9 & 0.320 & 0.51 & 1.8 & 0.341 & 17 &  56 & 0.9969 & 3.04 & 1.08 &  9.2 & 6\\\\\n",
       "\t  8.9 & 0.220 & 0.48 & 1.8 & 0.077 & 29 &  60 & 0.9968 & 3.39 & 0.53 &  9.4 & 6\\\\\n",
       "\t  7.6 & 0.390 & 0.31 & 2.3 & 0.082 & 23 &  71 & 0.9982 & 3.52 & 0.65 &  9.7 & 5\\\\\n",
       "\t  7.9 & 0.430 & 0.21 & 1.6 & 0.106 & 10 &  37 & 0.9966 & 3.17 & 0.91 &  9.5 & 5\\\\\n",
       "\t  8.5 & 0.490 & 0.11 & 2.3 & 0.084 &  9 &  67 & 0.9968 & 3.17 & 0.53 &  9.4 & 5\\\\\n",
       "\t  6.9 & 0.400 & 0.14 & 2.4 & 0.085 & 21 &  40 & 0.9968 & 3.43 & 0.63 &  9.7 & 6\\\\\n",
       "\t  6.3 & 0.390 & 0.16 & 1.4 & 0.080 & 11 &  23 & 0.9955 & 3.34 & 0.56 &  9.3 & 5\\\\\n",
       "\t  7.6 & 0.410 & 0.24 & 1.8 & 0.080 &  4 &  11 & 0.9962 & 3.28 & 0.59 &  9.5 & 5\\\\\n",
       "\t  7.9 & 0.430 & 0.21 & 1.6 & 0.106 & 10 &  37 & 0.9966 & 3.17 & 0.91 &  9.5 & 5\\\\\n",
       "\t  7.1 & 0.710 & 0.00 & 1.9 & 0.080 & 14 &  35 & 0.9972 & 3.47 & 0.55 &  9.4 & 5\\\\\n",
       "\t  7.8 & 0.645 & 0.00 & 2.0 & 0.082 &  8 &  16 & 0.9964 & 3.38 & 0.59 &  9.8 & 6\\\\\n",
       "\t ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮ & ⋮\\\\\n",
       "\t 6.2 & 0.510 & 0.14 &  1.9 & 0.056 & 15 &  34 & 0.99396 & 3.48 & 0.57 & 11.5 & 6\\\\\n",
       "\t 6.4 & 0.360 & 0.53 &  2.2 & 0.230 & 19 &  35 & 0.99340 & 3.37 & 0.93 & 12.4 & 6\\\\\n",
       "\t 6.4 & 0.380 & 0.14 &  2.2 & 0.038 & 15 &  25 & 0.99514 & 3.44 & 0.65 & 11.1 & 6\\\\\n",
       "\t 7.3 & 0.690 & 0.32 &  2.2 & 0.069 & 35 & 104 & 0.99632 & 3.33 & 0.51 &  9.5 & 5\\\\\n",
       "\t 6.0 & 0.580 & 0.20 &  2.4 & 0.075 & 15 &  50 & 0.99467 & 3.58 & 0.67 & 12.5 & 6\\\\\n",
       "\t 5.6 & 0.310 & 0.78 & 13.9 & 0.074 & 23 &  92 & 0.99677 & 3.39 & 0.48 & 10.5 & 6\\\\\n",
       "\t 7.5 & 0.520 & 0.40 &  2.2 & 0.060 & 12 &  20 & 0.99474 & 3.26 & 0.64 & 11.8 & 6\\\\\n",
       "\t 8.0 & 0.300 & 0.63 &  1.6 & 0.081 & 16 &  29 & 0.99588 & 3.30 & 0.78 & 10.8 & 6\\\\\n",
       "\t 6.2 & 0.700 & 0.15 &  5.1 & 0.076 & 13 &  27 & 0.99622 & 3.54 & 0.60 & 11.9 & 6\\\\\n",
       "\t 6.8 & 0.670 & 0.15 &  1.8 & 0.118 & 13 &  20 & 0.99540 & 3.42 & 0.67 & 11.3 & 6\\\\\n",
       "\t 6.2 & 0.560 & 0.09 &  1.7 & 0.053 & 24 &  32 & 0.99402 & 3.54 & 0.60 & 11.3 & 5\\\\\n",
       "\t 7.4 & 0.350 & 0.33 &  2.4 & 0.068 &  9 &  26 & 0.99470 & 3.36 & 0.60 & 11.9 & 6\\\\\n",
       "\t 6.2 & 0.560 & 0.09 &  1.7 & 0.053 & 24 &  32 & 0.99402 & 3.54 & 0.60 & 11.3 & 5\\\\\n",
       "\t 6.1 & 0.715 & 0.10 &  2.6 & 0.053 & 13 &  27 & 0.99362 & 3.57 & 0.50 & 11.9 & 5\\\\\n",
       "\t 6.2 & 0.460 & 0.29 &  2.1 & 0.074 & 32 &  98 & 0.99578 & 3.33 & 0.62 &  9.8 & 5\\\\\n",
       "\t 6.7 & 0.320 & 0.44 &  2.4 & 0.061 & 24 &  34 & 0.99484 & 3.29 & 0.80 & 11.6 & 7\\\\\n",
       "\t 7.2 & 0.390 & 0.44 &  2.6 & 0.066 & 22 &  48 & 0.99494 & 3.30 & 0.84 & 11.5 & 6\\\\\n",
       "\t 7.5 & 0.310 & 0.41 &  2.4 & 0.065 & 34 &  60 & 0.99492 & 3.34 & 0.85 & 11.4 & 6\\\\\n",
       "\t 5.8 & 0.610 & 0.11 &  1.8 & 0.066 & 18 &  28 & 0.99483 & 3.55 & 0.66 & 10.9 & 6\\\\\n",
       "\t 7.2 & 0.660 & 0.33 &  2.5 & 0.068 & 34 & 102 & 0.99414 & 3.27 & 0.78 & 12.8 & 6\\\\\n",
       "\t 6.6 & 0.725 & 0.20 &  7.8 & 0.073 & 29 &  79 & 0.99770 & 3.29 & 0.54 &  9.2 & 5\\\\\n",
       "\t 6.3 & 0.550 & 0.15 &  1.8 & 0.077 & 26 &  35 & 0.99314 & 3.32 & 0.82 & 11.6 & 6\\\\\n",
       "\t 5.4 & 0.740 & 0.09 &  1.7 & 0.089 & 16 &  26 & 0.99402 & 3.67 & 0.56 & 11.6 & 6\\\\\n",
       "\t 6.3 & 0.510 & 0.13 &  2.3 & 0.076 & 29 &  40 & 0.99574 & 3.42 & 0.75 & 11.0 & 6\\\\\n",
       "\t 6.8 & 0.620 & 0.08 &  1.9 & 0.068 & 28 &  38 & 0.99651 & 3.42 & 0.82 &  9.5 & 6\\\\\n",
       "\t 6.2 & 0.600 & 0.08 &  2.0 & 0.090 & 32 &  44 & 0.99490 & 3.45 & 0.58 & 10.5 & 5\\\\\n",
       "\t 5.9 & 0.550 & 0.10 &  2.2 & 0.062 & 39 &  51 & 0.99512 & 3.52 & 0.76 & 11.2 & 6\\\\\n",
       "\t 6.3 & 0.510 & 0.13 &  2.3 & 0.076 & 29 &  40 & 0.99574 & 3.42 & 0.75 & 11.0 & 6\\\\\n",
       "\t 5.9 & 0.645 & 0.12 &  2.0 & 0.075 & 32 &  44 & 0.99547 & 3.57 & 0.71 & 10.2 & 5\\\\\n",
       "\t 6.0 & 0.310 & 0.47 &  3.6 & 0.067 & 18 &  42 & 0.99549 & 3.39 & 0.66 & 11.0 & 6\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1599 × 12\n",
       "\n",
       "| _____________ &lt;dbl&gt; | ________________ &lt;dbl&gt; | ___________ &lt;dbl&gt; | ______________ &lt;dbl&gt; | _________ &lt;dbl&gt; | ___________________ &lt;dbl&gt; | ____________________ &lt;dbl&gt; | _______ &lt;dbl&gt; | __ &lt;dbl&gt; | _________ &lt;dbl&gt; | _______ &lt;dbl&gt; | _______ &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "|  7.4 | 0.700 | 0.00 | 1.9 | 0.076 | 11 |  34 | 0.9978 | 3.51 | 0.56 |  9.4 | 5 |\n",
       "|  7.8 | 0.880 | 0.00 | 2.6 | 0.098 | 25 |  67 | 0.9968 | 3.20 | 0.68 |  9.8 | 5 |\n",
       "|  7.8 | 0.760 | 0.04 | 2.3 | 0.092 | 15 |  54 | 0.9970 | 3.26 | 0.65 |  9.8 | 5 |\n",
       "| 11.2 | 0.280 | 0.56 | 1.9 | 0.075 | 17 |  60 | 0.9980 | 3.16 | 0.58 |  9.8 | 6 |\n",
       "|  7.4 | 0.700 | 0.00 | 1.9 | 0.076 | 11 |  34 | 0.9978 | 3.51 | 0.56 |  9.4 | 5 |\n",
       "|  7.4 | 0.660 | 0.00 | 1.8 | 0.075 | 13 |  40 | 0.9978 | 3.51 | 0.56 |  9.4 | 5 |\n",
       "|  7.9 | 0.600 | 0.06 | 1.6 | 0.069 | 15 |  59 | 0.9964 | 3.30 | 0.46 |  9.4 | 5 |\n",
       "|  7.3 | 0.650 | 0.00 | 1.2 | 0.065 | 15 |  21 | 0.9946 | 3.39 | 0.47 | 10.0 | 7 |\n",
       "|  7.8 | 0.580 | 0.02 | 2.0 | 0.073 |  9 |  18 | 0.9968 | 3.36 | 0.57 |  9.5 | 7 |\n",
       "|  7.5 | 0.500 | 0.36 | 6.1 | 0.071 | 17 | 102 | 0.9978 | 3.35 | 0.80 | 10.5 | 5 |\n",
       "|  6.7 | 0.580 | 0.08 | 1.8 | 0.097 | 15 |  65 | 0.9959 | 3.28 | 0.54 |  9.2 | 5 |\n",
       "|  7.5 | 0.500 | 0.36 | 6.1 | 0.071 | 17 | 102 | 0.9978 | 3.35 | 0.80 | 10.5 | 5 |\n",
       "|  5.6 | 0.615 | 0.00 | 1.6 | 0.089 | 16 |  59 | 0.9943 | 3.58 | 0.52 |  9.9 | 5 |\n",
       "|  7.8 | 0.610 | 0.29 | 1.6 | 0.114 |  9 |  29 | 0.9974 | 3.26 | 1.56 |  9.1 | 5 |\n",
       "|  8.9 | 0.620 | 0.18 | 3.8 | 0.176 | 52 | 145 | 0.9986 | 3.16 | 0.88 |  9.2 | 5 |\n",
       "|  8.9 | 0.620 | 0.19 | 3.9 | 0.170 | 51 | 148 | 0.9986 | 3.17 | 0.93 |  9.2 | 5 |\n",
       "|  8.5 | 0.280 | 0.56 | 1.8 | 0.092 | 35 | 103 | 0.9969 | 3.30 | 0.75 | 10.5 | 7 |\n",
       "|  8.1 | 0.560 | 0.28 | 1.7 | 0.368 | 16 |  56 | 0.9968 | 3.11 | 1.28 |  9.3 | 5 |\n",
       "|  7.4 | 0.590 | 0.08 | 4.4 | 0.086 |  6 |  29 | 0.9974 | 3.38 | 0.50 |  9.0 | 4 |\n",
       "|  7.9 | 0.320 | 0.51 | 1.8 | 0.341 | 17 |  56 | 0.9969 | 3.04 | 1.08 |  9.2 | 6 |\n",
       "|  8.9 | 0.220 | 0.48 | 1.8 | 0.077 | 29 |  60 | 0.9968 | 3.39 | 0.53 |  9.4 | 6 |\n",
       "|  7.6 | 0.390 | 0.31 | 2.3 | 0.082 | 23 |  71 | 0.9982 | 3.52 | 0.65 |  9.7 | 5 |\n",
       "|  7.9 | 0.430 | 0.21 | 1.6 | 0.106 | 10 |  37 | 0.9966 | 3.17 | 0.91 |  9.5 | 5 |\n",
       "|  8.5 | 0.490 | 0.11 | 2.3 | 0.084 |  9 |  67 | 0.9968 | 3.17 | 0.53 |  9.4 | 5 |\n",
       "|  6.9 | 0.400 | 0.14 | 2.4 | 0.085 | 21 |  40 | 0.9968 | 3.43 | 0.63 |  9.7 | 6 |\n",
       "|  6.3 | 0.390 | 0.16 | 1.4 | 0.080 | 11 |  23 | 0.9955 | 3.34 | 0.56 |  9.3 | 5 |\n",
       "|  7.6 | 0.410 | 0.24 | 1.8 | 0.080 |  4 |  11 | 0.9962 | 3.28 | 0.59 |  9.5 | 5 |\n",
       "|  7.9 | 0.430 | 0.21 | 1.6 | 0.106 | 10 |  37 | 0.9966 | 3.17 | 0.91 |  9.5 | 5 |\n",
       "|  7.1 | 0.710 | 0.00 | 1.9 | 0.080 | 14 |  35 | 0.9972 | 3.47 | 0.55 |  9.4 | 5 |\n",
       "|  7.8 | 0.645 | 0.00 | 2.0 | 0.082 |  8 |  16 | 0.9964 | 3.38 | 0.59 |  9.8 | 6 |\n",
       "| ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ | ⋮ |\n",
       "| 6.2 | 0.510 | 0.14 |  1.9 | 0.056 | 15 |  34 | 0.99396 | 3.48 | 0.57 | 11.5 | 6 |\n",
       "| 6.4 | 0.360 | 0.53 |  2.2 | 0.230 | 19 |  35 | 0.99340 | 3.37 | 0.93 | 12.4 | 6 |\n",
       "| 6.4 | 0.380 | 0.14 |  2.2 | 0.038 | 15 |  25 | 0.99514 | 3.44 | 0.65 | 11.1 | 6 |\n",
       "| 7.3 | 0.690 | 0.32 |  2.2 | 0.069 | 35 | 104 | 0.99632 | 3.33 | 0.51 |  9.5 | 5 |\n",
       "| 6.0 | 0.580 | 0.20 |  2.4 | 0.075 | 15 |  50 | 0.99467 | 3.58 | 0.67 | 12.5 | 6 |\n",
       "| 5.6 | 0.310 | 0.78 | 13.9 | 0.074 | 23 |  92 | 0.99677 | 3.39 | 0.48 | 10.5 | 6 |\n",
       "| 7.5 | 0.520 | 0.40 |  2.2 | 0.060 | 12 |  20 | 0.99474 | 3.26 | 0.64 | 11.8 | 6 |\n",
       "| 8.0 | 0.300 | 0.63 |  1.6 | 0.081 | 16 |  29 | 0.99588 | 3.30 | 0.78 | 10.8 | 6 |\n",
       "| 6.2 | 0.700 | 0.15 |  5.1 | 0.076 | 13 |  27 | 0.99622 | 3.54 | 0.60 | 11.9 | 6 |\n",
       "| 6.8 | 0.670 | 0.15 |  1.8 | 0.118 | 13 |  20 | 0.99540 | 3.42 | 0.67 | 11.3 | 6 |\n",
       "| 6.2 | 0.560 | 0.09 |  1.7 | 0.053 | 24 |  32 | 0.99402 | 3.54 | 0.60 | 11.3 | 5 |\n",
       "| 7.4 | 0.350 | 0.33 |  2.4 | 0.068 |  9 |  26 | 0.99470 | 3.36 | 0.60 | 11.9 | 6 |\n",
       "| 6.2 | 0.560 | 0.09 |  1.7 | 0.053 | 24 |  32 | 0.99402 | 3.54 | 0.60 | 11.3 | 5 |\n",
       "| 6.1 | 0.715 | 0.10 |  2.6 | 0.053 | 13 |  27 | 0.99362 | 3.57 | 0.50 | 11.9 | 5 |\n",
       "| 6.2 | 0.460 | 0.29 |  2.1 | 0.074 | 32 |  98 | 0.99578 | 3.33 | 0.62 |  9.8 | 5 |\n",
       "| 6.7 | 0.320 | 0.44 |  2.4 | 0.061 | 24 |  34 | 0.99484 | 3.29 | 0.80 | 11.6 | 7 |\n",
       "| 7.2 | 0.390 | 0.44 |  2.6 | 0.066 | 22 |  48 | 0.99494 | 3.30 | 0.84 | 11.5 | 6 |\n",
       "| 7.5 | 0.310 | 0.41 |  2.4 | 0.065 | 34 |  60 | 0.99492 | 3.34 | 0.85 | 11.4 | 6 |\n",
       "| 5.8 | 0.610 | 0.11 |  1.8 | 0.066 | 18 |  28 | 0.99483 | 3.55 | 0.66 | 10.9 | 6 |\n",
       "| 7.2 | 0.660 | 0.33 |  2.5 | 0.068 | 34 | 102 | 0.99414 | 3.27 | 0.78 | 12.8 | 6 |\n",
       "| 6.6 | 0.725 | 0.20 |  7.8 | 0.073 | 29 |  79 | 0.99770 | 3.29 | 0.54 |  9.2 | 5 |\n",
       "| 6.3 | 0.550 | 0.15 |  1.8 | 0.077 | 26 |  35 | 0.99314 | 3.32 | 0.82 | 11.6 | 6 |\n",
       "| 5.4 | 0.740 | 0.09 |  1.7 | 0.089 | 16 |  26 | 0.99402 | 3.67 | 0.56 | 11.6 | 6 |\n",
       "| 6.3 | 0.510 | 0.13 |  2.3 | 0.076 | 29 |  40 | 0.99574 | 3.42 | 0.75 | 11.0 | 6 |\n",
       "| 6.8 | 0.620 | 0.08 |  1.9 | 0.068 | 28 |  38 | 0.99651 | 3.42 | 0.82 |  9.5 | 6 |\n",
       "| 6.2 | 0.600 | 0.08 |  2.0 | 0.090 | 32 |  44 | 0.99490 | 3.45 | 0.58 | 10.5 | 5 |\n",
       "| 5.9 | 0.550 | 0.10 |  2.2 | 0.062 | 39 |  51 | 0.99512 | 3.52 | 0.76 | 11.2 | 6 |\n",
       "| 6.3 | 0.510 | 0.13 |  2.3 | 0.076 | 29 |  40 | 0.99574 | 3.42 | 0.75 | 11.0 | 6 |\n",
       "| 5.9 | 0.645 | 0.12 |  2.0 | 0.075 | 32 |  44 | 0.99547 | 3.57 | 0.71 | 10.2 | 5 |\n",
       "| 6.0 | 0.310 | 0.47 |  3.6 | 0.067 | 18 |  42 | 0.99549 | 3.39 | 0.66 | 11.0 | 6 |\n",
       "\n"
      ],
      "text/plain": [
       "     _____________ ________________ ___________ ______________ _________\n",
       "1     7.4          0.700            0.00        1.9            0.076    \n",
       "2     7.8          0.880            0.00        2.6            0.098    \n",
       "3     7.8          0.760            0.04        2.3            0.092    \n",
       "4    11.2          0.280            0.56        1.9            0.075    \n",
       "5     7.4          0.700            0.00        1.9            0.076    \n",
       "6     7.4          0.660            0.00        1.8            0.075    \n",
       "7     7.9          0.600            0.06        1.6            0.069    \n",
       "8     7.3          0.650            0.00        1.2            0.065    \n",
       "9     7.8          0.580            0.02        2.0            0.073    \n",
       "10    7.5          0.500            0.36        6.1            0.071    \n",
       "11    6.7          0.580            0.08        1.8            0.097    \n",
       "12    7.5          0.500            0.36        6.1            0.071    \n",
       "13    5.6          0.615            0.00        1.6            0.089    \n",
       "14    7.8          0.610            0.29        1.6            0.114    \n",
       "15    8.9          0.620            0.18        3.8            0.176    \n",
       "16    8.9          0.620            0.19        3.9            0.170    \n",
       "17    8.5          0.280            0.56        1.8            0.092    \n",
       "18    8.1          0.560            0.28        1.7            0.368    \n",
       "19    7.4          0.590            0.08        4.4            0.086    \n",
       "20    7.9          0.320            0.51        1.8            0.341    \n",
       "21    8.9          0.220            0.48        1.8            0.077    \n",
       "22    7.6          0.390            0.31        2.3            0.082    \n",
       "23    7.9          0.430            0.21        1.6            0.106    \n",
       "24    8.5          0.490            0.11        2.3            0.084    \n",
       "25    6.9          0.400            0.14        2.4            0.085    \n",
       "26    6.3          0.390            0.16        1.4            0.080    \n",
       "27    7.6          0.410            0.24        1.8            0.080    \n",
       "28    7.9          0.430            0.21        1.6            0.106    \n",
       "29    7.1          0.710            0.00        1.9            0.080    \n",
       "30    7.8          0.645            0.00        2.0            0.082    \n",
       "⋮    ⋮             ⋮                ⋮           ⋮              ⋮        \n",
       "1570 6.2           0.510            0.14         1.9           0.056    \n",
       "1571 6.4           0.360            0.53         2.2           0.230    \n",
       "1572 6.4           0.380            0.14         2.2           0.038    \n",
       "1573 7.3           0.690            0.32         2.2           0.069    \n",
       "1574 6.0           0.580            0.20         2.4           0.075    \n",
       "1575 5.6           0.310            0.78        13.9           0.074    \n",
       "1576 7.5           0.520            0.40         2.2           0.060    \n",
       "1577 8.0           0.300            0.63         1.6           0.081    \n",
       "1578 6.2           0.700            0.15         5.1           0.076    \n",
       "1579 6.8           0.670            0.15         1.8           0.118    \n",
       "1580 6.2           0.560            0.09         1.7           0.053    \n",
       "1581 7.4           0.350            0.33         2.4           0.068    \n",
       "1582 6.2           0.560            0.09         1.7           0.053    \n",
       "1583 6.1           0.715            0.10         2.6           0.053    \n",
       "1584 6.2           0.460            0.29         2.1           0.074    \n",
       "1585 6.7           0.320            0.44         2.4           0.061    \n",
       "1586 7.2           0.390            0.44         2.6           0.066    \n",
       "1587 7.5           0.310            0.41         2.4           0.065    \n",
       "1588 5.8           0.610            0.11         1.8           0.066    \n",
       "1589 7.2           0.660            0.33         2.5           0.068    \n",
       "1590 6.6           0.725            0.20         7.8           0.073    \n",
       "1591 6.3           0.550            0.15         1.8           0.077    \n",
       "1592 5.4           0.740            0.09         1.7           0.089    \n",
       "1593 6.3           0.510            0.13         2.3           0.076    \n",
       "1594 6.8           0.620            0.08         1.9           0.068    \n",
       "1595 6.2           0.600            0.08         2.0           0.090    \n",
       "1596 5.9           0.550            0.10         2.2           0.062    \n",
       "1597 6.3           0.510            0.13         2.3           0.076    \n",
       "1598 5.9           0.645            0.12         2.0           0.075    \n",
       "1599 6.0           0.310            0.47         3.6           0.067    \n",
       "     ___________________ ____________________ _______ __   _________ _______\n",
       "1    11                   34                  0.9978  3.51 0.56       9.4   \n",
       "2    25                   67                  0.9968  3.20 0.68       9.8   \n",
       "3    15                   54                  0.9970  3.26 0.65       9.8   \n",
       "4    17                   60                  0.9980  3.16 0.58       9.8   \n",
       "5    11                   34                  0.9978  3.51 0.56       9.4   \n",
       "6    13                   40                  0.9978  3.51 0.56       9.4   \n",
       "7    15                   59                  0.9964  3.30 0.46       9.4   \n",
       "8    15                   21                  0.9946  3.39 0.47      10.0   \n",
       "9     9                   18                  0.9968  3.36 0.57       9.5   \n",
       "10   17                  102                  0.9978  3.35 0.80      10.5   \n",
       "11   15                   65                  0.9959  3.28 0.54       9.2   \n",
       "12   17                  102                  0.9978  3.35 0.80      10.5   \n",
       "13   16                   59                  0.9943  3.58 0.52       9.9   \n",
       "14    9                   29                  0.9974  3.26 1.56       9.1   \n",
       "15   52                  145                  0.9986  3.16 0.88       9.2   \n",
       "16   51                  148                  0.9986  3.17 0.93       9.2   \n",
       "17   35                  103                  0.9969  3.30 0.75      10.5   \n",
       "18   16                   56                  0.9968  3.11 1.28       9.3   \n",
       "19    6                   29                  0.9974  3.38 0.50       9.0   \n",
       "20   17                   56                  0.9969  3.04 1.08       9.2   \n",
       "21   29                   60                  0.9968  3.39 0.53       9.4   \n",
       "22   23                   71                  0.9982  3.52 0.65       9.7   \n",
       "23   10                   37                  0.9966  3.17 0.91       9.5   \n",
       "24    9                   67                  0.9968  3.17 0.53       9.4   \n",
       "25   21                   40                  0.9968  3.43 0.63       9.7   \n",
       "26   11                   23                  0.9955  3.34 0.56       9.3   \n",
       "27    4                   11                  0.9962  3.28 0.59       9.5   \n",
       "28   10                   37                  0.9966  3.17 0.91       9.5   \n",
       "29   14                   35                  0.9972  3.47 0.55       9.4   \n",
       "30    8                   16                  0.9964  3.38 0.59       9.8   \n",
       "⋮    ⋮                   ⋮                    ⋮       ⋮    ⋮         ⋮      \n",
       "1570 15                   34                  0.99396 3.48 0.57      11.5   \n",
       "1571 19                   35                  0.99340 3.37 0.93      12.4   \n",
       "1572 15                   25                  0.99514 3.44 0.65      11.1   \n",
       "1573 35                  104                  0.99632 3.33 0.51       9.5   \n",
       "1574 15                   50                  0.99467 3.58 0.67      12.5   \n",
       "1575 23                   92                  0.99677 3.39 0.48      10.5   \n",
       "1576 12                   20                  0.99474 3.26 0.64      11.8   \n",
       "1577 16                   29                  0.99588 3.30 0.78      10.8   \n",
       "1578 13                   27                  0.99622 3.54 0.60      11.9   \n",
       "1579 13                   20                  0.99540 3.42 0.67      11.3   \n",
       "1580 24                   32                  0.99402 3.54 0.60      11.3   \n",
       "1581  9                   26                  0.99470 3.36 0.60      11.9   \n",
       "1582 24                   32                  0.99402 3.54 0.60      11.3   \n",
       "1583 13                   27                  0.99362 3.57 0.50      11.9   \n",
       "1584 32                   98                  0.99578 3.33 0.62       9.8   \n",
       "1585 24                   34                  0.99484 3.29 0.80      11.6   \n",
       "1586 22                   48                  0.99494 3.30 0.84      11.5   \n",
       "1587 34                   60                  0.99492 3.34 0.85      11.4   \n",
       "1588 18                   28                  0.99483 3.55 0.66      10.9   \n",
       "1589 34                  102                  0.99414 3.27 0.78      12.8   \n",
       "1590 29                   79                  0.99770 3.29 0.54       9.2   \n",
       "1591 26                   35                  0.99314 3.32 0.82      11.6   \n",
       "1592 16                   26                  0.99402 3.67 0.56      11.6   \n",
       "1593 29                   40                  0.99574 3.42 0.75      11.0   \n",
       "1594 28                   38                  0.99651 3.42 0.82       9.5   \n",
       "1595 32                   44                  0.99490 3.45 0.58      10.5   \n",
       "1596 39                   51                  0.99512 3.52 0.76      11.2   \n",
       "1597 29                   40                  0.99574 3.42 0.75      11.0   \n",
       "1598 32                   44                  0.99547 3.57 0.71      10.2   \n",
       "1599 18                   42                  0.99549 3.39 0.66      11.0   \n",
       "     _______\n",
       "1    5      \n",
       "2    5      \n",
       "3    5      \n",
       "4    6      \n",
       "5    5      \n",
       "6    5      \n",
       "7    5      \n",
       "8    7      \n",
       "9    7      \n",
       "10   5      \n",
       "11   5      \n",
       "12   5      \n",
       "13   5      \n",
       "14   5      \n",
       "15   5      \n",
       "16   5      \n",
       "17   7      \n",
       "18   5      \n",
       "19   4      \n",
       "20   6      \n",
       "21   6      \n",
       "22   5      \n",
       "23   5      \n",
       "24   5      \n",
       "25   6      \n",
       "26   5      \n",
       "27   5      \n",
       "28   5      \n",
       "29   5      \n",
       "30   6      \n",
       "⋮    ⋮      \n",
       "1570 6      \n",
       "1571 6      \n",
       "1572 6      \n",
       "1573 5      \n",
       "1574 6      \n",
       "1575 6      \n",
       "1576 6      \n",
       "1577 6      \n",
       "1578 6      \n",
       "1579 6      \n",
       "1580 5      \n",
       "1581 6      \n",
       "1582 5      \n",
       "1583 5      \n",
       "1584 5      \n",
       "1585 7      \n",
       "1586 6      \n",
       "1587 6      \n",
       "1588 6      \n",
       "1589 6      \n",
       "1590 5      \n",
       "1591 6      \n",
       "1592 6      \n",
       "1593 6      \n",
       "1594 6      \n",
       "1595 5      \n",
       "1596 6      \n",
       "1597 6      \n",
       "1598 5      \n",
       "1599 6      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cleaning and wrangling data\n",
    "colnames(data) <- gsub(\"'.'\", \"_\", names(data))\n",
    "colnames(data)[colnames(data) %in% c(\"free_sulfur_dioxide\", \"total_sulfur_dioxide\")] <- c(\"free_so2\", \"total_so2\")\n",
    "data\n",
    "# clean_data <- data %>%\n",
    "#               mutate(quality = as_factor(quality))\n",
    "# %>%\n",
    "#               subset(select = -c(fixed_acidity, volatile_acidity, citric_acid, free_so2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data\n",
    "set.seed(7)\n",
    "clean_data_split <- initial_split(clean_data, prop = 0.5, strata = quality)\n",
    "train_data <- training(clean_data_split)\n",
    "test_data <- testing(clean_data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 801\n",
      "Columns: 12\n",
      "$ fixed.acidity        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 11.2, 7.4, 7.9, 7.8, 6.7, 7.8, 8.9, 7.4, 8.5, 7.…\n",
      "$ volatile.acidity     \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0.280, 0.700, 0.600, 0.580, 0.580, 0.610, 0.620,…\n",
      "$ citric.acid          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0.56, 0.00, 0.06, 0.02, 0.08, 0.29, 0.18, 0.08, …\n",
      "$ residual.sugar       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 1.9, 1.9, 1.6, 2.0, 1.8, 1.6, 3.8, 4.4, 2.3, 1.8…\n",
      "$ chlorides            \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0.075, 0.076, 0.069, 0.073, 0.097, 0.114, 0.176,…\n",
      "$ free.sulfur.dioxide  \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 17, 11, 15, 9, 15, 9, 52, 6, 9, 4, 10, 17, 22, 1…\n",
      "$ total.sulfur.dioxide \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 60, 34, 59, 18, 65, 29, 145, 29, 67, 11, 37, 82,…\n",
      "$ density              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0.9980, 0.9978, 0.9964, 0.9968, 0.9959, 0.9974, …\n",
      "$ pH                   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 3.16, 3.51, 3.30, 3.36, 3.28, 3.26, 3.16, 3.38, …\n",
      "$ sulphates            \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0.58, 0.56, 0.46, 0.57, 0.54, 1.56, 0.88, 0.50, …\n",
      "$ alcohol              \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 9.8, 9.4, 9.4, 9.5, 9.2, 9.1, 9.2, 9.0, 9.4, 9.5…\n",
      "$ quality              \u001b[3m\u001b[90m<fct>\u001b[39m\u001b[23m 6, 5, 5, 7, 5, 5, 5, 4, 5, 5, 5, 5, 6, 5, 6, 5, …\n"
     ]
    }
   ],
   "source": [
    "glimpse(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`summarise()` ungrouping output (override with `.groups` argument)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# summarizing data\n",
    "train_data_mean_summary <- train_data %>%\n",
    "                           mutate(quality = as.numeric(quality)) %>%\n",
    "                           map_dfr(mean, na.rm = TRUE)\n",
    "\n",
    "colnames(train_data_mean_summary) <- paste(\"mean\", colnames(train_data_mean_summary), sep = \"_\")\n",
    "\n",
    "train_data_quality_summary <- train_data %>%\n",
    "                              group_by(quality) %>%\n",
    "                              summarize(count = n(),\n",
    "                                        proportion = n() / nrow(train_data) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 1 × 12</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>mean_fixed.acidity</th><th scope=col>mean_volatile.acidity</th><th scope=col>mean_citric.acid</th><th scope=col>mean_residual.sugar</th><th scope=col>mean_chlorides</th><th scope=col>mean_free.sulfur.dioxide</th><th scope=col>mean_total.sulfur.dioxide</th><th scope=col>mean_density</th><th scope=col>mean_pH</th><th scope=col>mean_sulphates</th><th scope=col>mean_alcohol</th><th scope=col>mean_quality</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>8.379401</td><td>0.5236267</td><td>0.2821473</td><td>2.563109</td><td>0.08929213</td><td>15.99438</td><td>46.72097</td><td>0.9967475</td><td>3.304257</td><td>0.6739201</td><td>10.4283</td><td>3.652934</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 1 × 12\n",
       "\\begin{tabular}{llllllllllll}\n",
       " mean\\_fixed.acidity & mean\\_volatile.acidity & mean\\_citric.acid & mean\\_residual.sugar & mean\\_chlorides & mean\\_free.sulfur.dioxide & mean\\_total.sulfur.dioxide & mean\\_density & mean\\_pH & mean\\_sulphates & mean\\_alcohol & mean\\_quality\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 8.379401 & 0.5236267 & 0.2821473 & 2.563109 & 0.08929213 & 15.99438 & 46.72097 & 0.9967475 & 3.304257 & 0.6739201 & 10.4283 & 3.652934\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 1 × 12\n",
       "\n",
       "| mean_fixed.acidity &lt;dbl&gt; | mean_volatile.acidity &lt;dbl&gt; | mean_citric.acid &lt;dbl&gt; | mean_residual.sugar &lt;dbl&gt; | mean_chlorides &lt;dbl&gt; | mean_free.sulfur.dioxide &lt;dbl&gt; | mean_total.sulfur.dioxide &lt;dbl&gt; | mean_density &lt;dbl&gt; | mean_pH &lt;dbl&gt; | mean_sulphates &lt;dbl&gt; | mean_alcohol &lt;dbl&gt; | mean_quality &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 8.379401 | 0.5236267 | 0.2821473 | 2.563109 | 0.08929213 | 15.99438 | 46.72097 | 0.9967475 | 3.304257 | 0.6739201 | 10.4283 | 3.652934 |\n",
       "\n"
      ],
      "text/plain": [
       "  mean_fixed.acidity mean_volatile.acidity mean_citric.acid mean_residual.sugar\n",
       "1 8.379401           0.5236267             0.2821473        2.563109           \n",
       "  mean_chlorides mean_free.sulfur.dioxide mean_total.sulfur.dioxide\n",
       "1 0.08929213     15.99438                 46.72097                 \n",
       "  mean_density mean_pH  mean_sulphates mean_alcohol mean_quality\n",
       "1 0.9967475    3.304257 0.6739201      10.4283      3.652934    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mean of predictor variables and classifier\n",
    "train_data_mean_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 6 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>quality</th><th scope=col>count</th><th scope=col>proportion</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>3</td><td>  5</td><td> 0.6242197</td></tr>\n",
       "\t<tr><td>4</td><td> 24</td><td> 2.9962547</td></tr>\n",
       "\t<tr><td>5</td><td>342</td><td>42.6966292</td></tr>\n",
       "\t<tr><td>6</td><td>315</td><td>39.3258427</td></tr>\n",
       "\t<tr><td>7</td><td>103</td><td>12.8589263</td></tr>\n",
       "\t<tr><td>8</td><td> 12</td><td> 1.4981273</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 3\n",
       "\\begin{tabular}{lll}\n",
       " quality & count & proportion\\\\\n",
       " <fct> & <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 3 &   5 &  0.6242197\\\\\n",
       "\t 4 &  24 &  2.9962547\\\\\n",
       "\t 5 & 342 & 42.6966292\\\\\n",
       "\t 6 & 315 & 39.3258427\\\\\n",
       "\t 7 & 103 & 12.8589263\\\\\n",
       "\t 8 &  12 &  1.4981273\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 3\n",
       "\n",
       "| quality &lt;fct&gt; | count &lt;int&gt; | proportion &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 3 |   5 |  0.6242197 |\n",
       "| 4 |  24 |  2.9962547 |\n",
       "| 5 | 342 | 42.6966292 |\n",
       "| 6 | 315 | 39.3258427 |\n",
       "| 7 | 103 | 12.8589263 |\n",
       "| 8 |  12 |  1.4981273 |\n",
       "\n"
      ],
      "text/plain": [
       "  quality count proportion\n",
       "1 3         5    0.6242197\n",
       "2 4        24    2.9962547\n",
       "3 5       342   42.6966292\n",
       "4 6       315   39.3258427\n",
       "5 7       103   12.8589263\n",
       "6 8        12    1.4981273"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# count of classifier\n",
    "train_data_quality_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling data\n",
    "train_data_scaled <- train_data %>%\n",
    "                     mutate_at(vars(-quality, -pH),\n",
    "                               ~(scale(., center = TRUE) %>% as.vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing data\n",
    "alcohol_plot <- train_data %>%\n",
    "                ggplot(aes(x = quality, y = alcohol)) +\n",
    "                geom_boxplot() +\n",
    "                theme(text = element_text(size = 14))\n",
    "volatile_acidity_plot <- train_data %>%\n",
    "                      ggplot(aes(x = quality, y = volatile_acidity)) +\n",
    "                      geom_boxplot() +\n",
    "                      theme(text = element_text(size = 14))\n",
    "sulphates_plot <- train_data %>%\n",
    "                  ggplot(aes(x = quality, y = sulphates)) +\n",
    "                  geom_boxplot() +\n",
    "                  theme(text = element_text(size = 14))\n",
    "total_so2_plot <- train_data %>%\n",
    "                  ggplot(aes(x = quality, y = total_so2)) +\n",
    "                  geom_boxplot() +\n",
    "                  theme(text = element_text(size = 14))\n",
    "chlorides_plot <- train_data %>%\n",
    "                   ggplot(aes(x = quality, y = chlorides)) +\n",
    "                   geom_boxplot() +\n",
    "                   theme(text = element_text(size = 14))\n",
    "residual_sugar_plot <- train_data %>%\n",
    "                       ggplot(aes(x = quality, y = residual_sugar)) +\n",
    "                       geom_boxplot() +\n",
    "                       theme(text = element_text(size = 14))\n",
    "\n",
    "train_data_quality_summary_plot <- train_data_quality_summary %>%\n",
    "                                   ggplot(aes(x = quality, y = count)) +\n",
    "                                   geom_bar(stat = \"identity\") +\n",
    "                                   labs(x = \"Quality\", y = \"Count\") +\n",
    "                                   theme(text = element_text(size = 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in FUN(X[[i]], ...): object 'volatile_acidity' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in FUN(X[[i]], ...): object 'volatile_acidity' not found\nTraceback:\n",
      "1. grid.arrange(alcohol_plot, volatile_acidity_plot, sulphates_plot, \n .     total_so2_plot, residual_sugar_plot, chlorides_plot, nrow = 1)",
      "2. arrangeGrob(...)",
      "3. lapply(grobs[toconv], ggplot2::ggplotGrob)",
      "4. FUN(X[[i]], ...)",
      "5. ggplot_gtable(ggplot_build(x))",
      "6. ggplot_build(x)",
      "7. ggplot_build.ggplot(x)",
      "8. by_layer(function(l, d) l$compute_aesthetics(d, plot))",
      "9. f(l = layers[[i]], d = data[[i]])",
      "10. l$compute_aesthetics(d, plot)",
      "11. f(..., self = self)",
      "12. scales_add_defaults(plot$scales, data, aesthetics, plot$plot_env)",
      "13. lapply(aesthetics[new_aesthetics], eval_tidy, data = data)",
      "14. FUN(X[[i]], ...)"
     ]
    }
   ],
   "source": [
    "# predictor variables boxplots\n",
    "options(repr.plot.width = 24, repr.plot.height = 4)\n",
    "summary_plot <- grid.arrange(alcohol_plot,\n",
    "                             volatile_acidity_plot,\n",
    "                             sulphates_plot,\n",
    "                             total_so2_plot,\n",
    "                             residual_sugar_plot,\n",
    "                             chlorides_plot,\n",
    "                             nrow=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplot of predictor values and quality, which we can use to potentially classify quality based off of where the predictor values lie by forming a line of best fit along the means and quartiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLAAAAHgCAMAAACCSWStAAAC31BMVEUAAAABAQECAgIDAwME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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 240,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# count of classifier plot\n",
    "options(repr.plot.width = 10, options.repr.plot.height = 15)\n",
    "train_data_quality_summary_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counts for every observable quality in the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data analysis will be conducted using a classification model (specifically k-nearest-neighbours). We will be using alcohol, volatile acidity, sulphates, total sulfur dioxide, residual sugar and chlorides — obtained from variable parameter selection — as our predictors to help predict and classify wine quality. When analyzing the outcomes, our results will be visualized using a bar plot.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Outcomes and Significance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect to see that our chosen predictors will greatly influence the quality of wine depending on their relative proportions. That is, we expect that all of our predictors have individual influence over the wine quality, and when combined in a model, each predictor acts to amplify the accuracy of the quality predictions.\n",
    "\n",
    "The impact of these findings may help improve the wine industry. In recent years, this industry is growing and thus there is an increased interest in investing in more innovative techniques that may enhance wine production as well as its selling. Our work aims to integrate subjective rankings to objective measures so that people can extrapolate these findings and make better quality wines. These variables are able to be controlled and manipulated during production. Thus, our findings may be used by oenologists to improve their wine production.\n",
    "\n",
    "Future questions that may arise include those concerned over what other potential factors may influence the quality of wine or whether the interaction between variables has a greater impact than considered singularly. Further assessment may attempt to discover relationships between variables that together produce a stronger prediction of wine quality. This analysis may also raise the question of whether subjective experience or objective measures matter most. It is possible that personal and sensory experiences play a larger role in shaping wine quality rankings. Therefore, further analysis may explore these subjective factors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Data Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold2: internal: No observations were detected in `truth` for level(s): '8'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold3: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n",
      "\u001b[33m!\u001b[39m \u001b[33mFold4: internal: No observations were detected in `truth` for level(s): '3'\n",
      "Com...\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 11 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>size</th><th scope=col>model_string</th><th scope=col>accuracy</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 1</td><td>quality ~ alcohol                                                                                                            </td><td>0.5268789</td></tr>\n",
       "\t<tr><td> 2</td><td>quality ~ alcohol+volatile_acidity                                                                                           </td><td>0.5680280</td></tr>\n",
       "\t<tr><td> 3</td><td>quality ~ alcohol+volatile_acidity+sulphates                                                                                 </td><td>0.5854891</td></tr>\n",
       "\t<tr><td> 4</td><td>quality ~ alcohol+volatile_acidity+sulphates+total_so2                                                                       </td><td>0.6017469</td></tr>\n",
       "\t<tr><td> 5</td><td>quality ~ alcohol+volatile_acidity+sulphates+total_so2+chlorides                                                             </td><td>0.6079503</td></tr>\n",
       "\t<tr><td> 6</td><td>quality ~ alcohol+volatile_acidity+sulphates+total_so2+chlorides+residual_sugar                                              </td><td>0.6117003</td></tr>\n",
       "\t<tr><td> 7</td><td>quality ~ alcohol+volatile_acidity+sulphates+total_so2+chlorides+residual_sugar+free_so2                                     </td><td>0.5955047</td></tr>\n",
       "\t<tr><td> 8</td><td>quality ~ alcohol+volatile_acidity+sulphates+total_so2+chlorides+residual_sugar+free_so2+fixed_acidity                       </td><td>0.5954891</td></tr>\n",
       "\t<tr><td> 9</td><td>quality ~ alcohol+volatile_acidity+sulphates+total_so2+chlorides+residual_sugar+free_so2+fixed_acidity+citric_acid           </td><td>0.5904814</td></tr>\n",
       "\t<tr><td>10</td><td>quality ~ alcohol+volatile_acidity+sulphates+total_so2+chlorides+residual_sugar+free_so2+fixed_acidity+citric_acid+density   </td><td>0.5829891</td></tr>\n",
       "\t<tr><td>11</td><td>quality ~ alcohol+volatile_acidity+sulphates+total_so2+chlorides+residual_sugar+free_so2+fixed_acidity+citric_acid+density+pH</td><td>0.5742391</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 11 × 3\n",
       "\\begin{tabular}{lll}\n",
       " size & model\\_string & accuracy\\\\\n",
       " <int> & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t  1 & quality \\textasciitilde{} alcohol                                                                                                             & 0.5268789\\\\\n",
       "\t  2 & quality \\textasciitilde{} alcohol+volatile\\_acidity                                                                                            & 0.5680280\\\\\n",
       "\t  3 & quality \\textasciitilde{} alcohol+volatile\\_acidity+sulphates                                                                                  & 0.5854891\\\\\n",
       "\t  4 & quality \\textasciitilde{} alcohol+volatile\\_acidity+sulphates+total\\_so2                                                                        & 0.6017469\\\\\n",
       "\t  5 & quality \\textasciitilde{} alcohol+volatile\\_acidity+sulphates+total\\_so2+chlorides                                                              & 0.6079503\\\\\n",
       "\t  6 & quality \\textasciitilde{} alcohol+volatile\\_acidity+sulphates+total\\_so2+chlorides+residual\\_sugar                                               & 0.6117003\\\\\n",
       "\t  7 & quality \\textasciitilde{} alcohol+volatile\\_acidity+sulphates+total\\_so2+chlorides+residual\\_sugar+free\\_so2                                      & 0.5955047\\\\\n",
       "\t  8 & quality \\textasciitilde{} alcohol+volatile\\_acidity+sulphates+total\\_so2+chlorides+residual\\_sugar+free\\_so2+fixed\\_acidity                        & 0.5954891\\\\\n",
       "\t  9 & quality \\textasciitilde{} alcohol+volatile\\_acidity+sulphates+total\\_so2+chlorides+residual\\_sugar+free\\_so2+fixed\\_acidity+citric\\_acid            & 0.5904814\\\\\n",
       "\t 10 & quality \\textasciitilde{} alcohol+volatile\\_acidity+sulphates+total\\_so2+chlorides+residual\\_sugar+free\\_so2+fixed\\_acidity+citric\\_acid+density    & 0.5829891\\\\\n",
       "\t 11 & quality \\textasciitilde{} alcohol+volatile\\_acidity+sulphates+total\\_so2+chlorides+residual\\_sugar+free\\_so2+fixed\\_acidity+citric\\_acid+density+pH & 0.5742391\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 11 × 3\n",
       "\n",
       "| size &lt;int&gt; | model_string &lt;chr&gt; | accuracy &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "|  1 | quality ~ alcohol                                                                                                             | 0.5268789 |\n",
       "|  2 | quality ~ alcohol+volatile_acidity                                                                                            | 0.5680280 |\n",
       "|  3 | quality ~ alcohol+volatile_acidity+sulphates                                                                                  | 0.5854891 |\n",
       "|  4 | quality ~ alcohol+volatile_acidity+sulphates+total_so2                                                                        | 0.6017469 |\n",
       "|  5 | quality ~ alcohol+volatile_acidity+sulphates+total_so2+chlorides                                                              | 0.6079503 |\n",
       "|  6 | quality ~ alcohol+volatile_acidity+sulphates+total_so2+chlorides+residual_sugar                                               | 0.6117003 |\n",
       "|  7 | quality ~ alcohol+volatile_acidity+sulphates+total_so2+chlorides+residual_sugar+free_so2                                      | 0.5955047 |\n",
       "|  8 | quality ~ alcohol+volatile_acidity+sulphates+total_so2+chlorides+residual_sugar+free_so2+fixed_acidity                        | 0.5954891 |\n",
       "|  9 | quality ~ alcohol+volatile_acidity+sulphates+total_so2+chlorides+residual_sugar+free_so2+fixed_acidity+citric_acid            | 0.5904814 |\n",
       "| 10 | quality ~ alcohol+volatile_acidity+sulphates+total_so2+chlorides+residual_sugar+free_so2+fixed_acidity+citric_acid+density    | 0.5829891 |\n",
       "| 11 | quality ~ alcohol+volatile_acidity+sulphates+total_so2+chlorides+residual_sugar+free_so2+fixed_acidity+citric_acid+density+pH | 0.5742391 |\n",
       "\n"
      ],
      "text/plain": [
       "   size\n",
       "1   1  \n",
       "2   2  \n",
       "3   3  \n",
       "4   4  \n",
       "5   5  \n",
       "6   6  \n",
       "7   7  \n",
       "8   8  \n",
       "9   9  \n",
       "10 10  \n",
       "11 11  \n",
       "   model_string                                                                                                                 \n",
       "1  quality ~ alcohol                                                                                                            \n",
       "2  quality ~ alcohol+volatile_acidity                                                                                           \n",
       "3  quality ~ alcohol+volatile_acidity+sulphates                                                                                 \n",
       "4  quality ~ alcohol+volatile_acidity+sulphates+total_so2                                                                       \n",
       "5  quality ~ alcohol+volatile_acidity+sulphates+total_so2+chlorides                                                             \n",
       "6  quality ~ alcohol+volatile_acidity+sulphates+total_so2+chlorides+residual_sugar                                              \n",
       "7  quality ~ alcohol+volatile_acidity+sulphates+total_so2+chlorides+residual_sugar+free_so2                                     \n",
       "8  quality ~ alcohol+volatile_acidity+sulphates+total_so2+chlorides+residual_sugar+free_so2+fixed_acidity                       \n",
       "9  quality ~ alcohol+volatile_acidity+sulphates+total_so2+chlorides+residual_sugar+free_so2+fixed_acidity+citric_acid           \n",
       "10 quality ~ alcohol+volatile_acidity+sulphates+total_so2+chlorides+residual_sugar+free_so2+fixed_acidity+citric_acid+density   \n",
       "11 quality ~ alcohol+volatile_acidity+sulphates+total_so2+chlorides+residual_sugar+free_so2+fixed_acidity+citric_acid+density+pH\n",
       "   accuracy \n",
       "1  0.5268789\n",
       "2  0.5680280\n",
       "3  0.5854891\n",
       "4  0.6017469\n",
       "5  0.6079503\n",
       "6  0.6117003\n",
       "7  0.5955047\n",
       "8  0.5954891\n",
       "9  0.5904814\n",
       "10 0.5829891\n",
       "11 0.5742391"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(7)\n",
    "\n",
    "# determining predictors\n",
    "data_subset <- train_data_scaled\n",
    "names <- colnames(data_subset %>% select(-quality))\n",
    "example_formula <- paste(\"quality\", \"~\", paste(names, collapse=\"+\"))\n",
    "\n",
    "# create an empty tibble to store the results\n",
    "accuracies <- tibble(size = integer(), \n",
    "                     model_string = character(), \n",
    "                     accuracy = numeric())\n",
    "\n",
    "# create a model specification\n",
    "spec <- nearest_neighbor(weight_func = \"rectangular\", \n",
    "                             neighbors = tune()) %>%\n",
    "     set_engine(\"kknn\") %>%\n",
    "     set_mode(\"classification\")\n",
    "\n",
    "# create a 5-fold cross-validation object\n",
    "data_vfold <- vfold_cv(data_subset, v = 5, strata = quality)\n",
    "\n",
    "# store the total number of predictors\n",
    "n_total <- length(names)\n",
    "\n",
    "# stores selected predictors\n",
    "selected <- c()\n",
    "\n",
    "# for every size from 1 to the total number of predictors\n",
    "for (i in 1:n_total) {\n",
    "    # for every predictor still not added yet\n",
    "    accs <- list()\n",
    "    models <- list()\n",
    "    for (j in 1:length(names)) {\n",
    "        # create a model string for this combination of predictors\n",
    "        preds_new <- c(selected, names[[j]])\n",
    "        model_string <- paste(\"quality\", \"~\", paste(preds_new, collapse=\"+\"))\n",
    "\n",
    "        # create a recipe from the model string\n",
    "        data_recipe <- recipe(as.formula(model_string), \n",
    "                                data = data_subset) %>%\n",
    "                          step_scale(all_predictors()) %>%\n",
    "                          step_center(all_predictors())\n",
    "\n",
    "        # tune the KNN classifier with these predictors, \n",
    "        # and collect the accuracy for the best K\n",
    "        acc <- workflow() %>%\n",
    "          add_recipe(data_recipe) %>%\n",
    "          add_model(spec) %>%\n",
    "          tune_grid(resamples = data_vfold, grid = 10) %>%\n",
    "          collect_metrics() %>%\n",
    "          filter(.metric == \"accuracy\") %>%\n",
    "          summarize(mx = max(mean))\n",
    "        acc <- acc$mx %>% unlist()\n",
    "\n",
    "        # add this result to the dataframe\n",
    "        accs[[j]] <- acc\n",
    "        models[[j]] <- model_string\n",
    "    }\n",
    "    jstar <- which.max(unlist(accs))\n",
    "    accuracies <- accuracies %>% \n",
    "      add_row(size = i, \n",
    "              model_string = models[[jstar]], \n",
    "              accuracy = accs[[jstar]])\n",
    "    selected <- c(selected, names[[jstar]])\n",
    "    names <- names[-jstar]\n",
    "}\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 1 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>.metric</th><th scope=col>.estimator</th><th scope=col>.estimate</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>accuracy</td><td>multiclass</td><td>0.6002506</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 1 × 3\n",
       "\\begin{tabular}{lll}\n",
       " .metric & .estimator & .estimate\\\\\n",
       " <chr> & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t accuracy & multiclass & 0.6002506\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 1 × 3\n",
       "\n",
       "| .metric &lt;chr&gt; | .estimator &lt;chr&gt; | .estimate &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| accuracy | multiclass | 0.6002506 |\n",
       "\n"
      ],
      "text/plain": [
       "  .metric  .estimator .estimate\n",
       "1 accuracy multiclass 0.6002506"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating a model\n",
    "\n",
    "predictor_train_data <- train_data %>% select(c(quality, alcohol, volatile_acidity, sulphates, total_so2, residual_sugar, chlorides))\n",
    "\n",
    "recipe <- recipe(quality ~., data = predictor_train_data) %>%\n",
    "step_scale(all_predictors()) %>%\n",
    "step_center(all_predictors())\n",
    "\n",
    "model <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) %>%\n",
    "set_engine(\"kknn\") %>%\n",
    "set_mode(\"classification\")\n",
    "\n",
    "vfold <- vfold_cv(predictor_train_data, v = 5, strata = quality)\n",
    "\n",
    "# code below yeilded a very variable k plot of accuracy, best k's = 60-75 best. All a accuracies around 0.56.\n",
    "# so i limited it to a smaller range.\n",
    "\n",
    "# k_vals <- tibble(neighbors = seq(1,100,5))\n",
    "\n",
    "# train_fit <- workflow() %>%\n",
    "# add_recipe(recipe) %>%\n",
    "# add_model(model) %>%\n",
    "# tune_grid(resamples = vfold, grid = k_vals) %>%\n",
    "# collect_metrics() %>%\n",
    "# filter(.metric == \"accuracy\") %>%\n",
    "# arrange(mean)\n",
    "\n",
    "# tail(train_fit)\n",
    "\n",
    "# k_plot <- ggplot(train_fit, aes(x=neighbors, y=mean)) + geom_point() + geom_line()\n",
    "# k_plot\n",
    "\n",
    "# code below yeilded a fairly variable k plot of accuracy, but k = 35 likely best for preventing under and overfitting.\n",
    "# k = 29 also does not vary as much from nearby points.\n",
    "\n",
    "# k_vals_2 <- tibble(neighbors = seq(60,90,2))\n",
    "\n",
    "# train_fit_2 <- workflow() %>%\n",
    "# add_recipe(recipe) %>%\n",
    "# add_model(model) %>%\n",
    "# tune_grid(resamples = vfold, grid = k_vals_2) %>%\n",
    "# collect_metrics() %>%\n",
    "# filter(.metric == \"accuracy\") %>%\n",
    "# arrange(mean)\n",
    "\n",
    "# tail(train_fit_2)\n",
    "\n",
    "# k_plot_2 <- ggplot(train_fit_2, aes(x=neighbors, y=mean)) + geom_point() + geom_line()\n",
    "# k_plot_2\n",
    "\n",
    "# using best model of k = 73, with accuracy 0.56.\n",
    "\n",
    "best_model <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 35) %>%\n",
    "set_engine(\"kknn\") %>%\n",
    "set_mode(\"classification\")\n",
    "\n",
    "train_fit <- workflow() %>%\n",
    "add_recipe(recipe) %>%\n",
    "add_model(best_model) %>%\n",
    "fit(predictor_train_data)\n",
    "\n",
    "predict_accuracy <- predict(train_fit, test_data) %>%\n",
    "bind_cols(test_data) %>%\n",
    "metrics(truth = quality, estimate = .pred_class) %>%\n",
    "filter(.metric == \"accuracy\")\n",
    "predict_accuracy\n",
    "\n",
    "# above code gives 0.5957447 evaluation accuracy which is better than chance alone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 1 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>.metric</th><th scope=col>.estimator</th><th scope=col>.estimate</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>accuracy</td><td>multiclass</td><td>0.5989975</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 1 × 3\n",
       "\\begin{tabular}{lll}\n",
       " .metric & .estimator & .estimate\\\\\n",
       " <chr> & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t accuracy & multiclass & 0.5989975\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 1 × 3\n",
       "\n",
       "| .metric &lt;chr&gt; | .estimator &lt;chr&gt; | .estimate &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| accuracy | multiclass | 0.5989975 |\n",
       "\n"
      ],
      "text/plain": [
       "  .metric  .estimator .estimate\n",
       "1 accuracy multiclass 0.5989975"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Wenwen did this... thx Wenwen :D\n",
    "\n",
    "# creating model using variable support vector machine from paper\n",
    "\n",
    "train_data_SVM <- train_data %>% \n",
    "    select(c(quality, fixed_acidity, alcohol, sulphates, total_so2, free_so2, volatile_acidity, pH))\n",
    "\n",
    "SVM_recipe <- recipe(quality ~., data = train_data_SVM) %>%\n",
    "    step_scale(all_predictors()) %>%\n",
    "    step_center(all_predictors())\n",
    "\n",
    "SVM_model <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) %>%\n",
    "    set_engine(\"kknn\") %>%\n",
    "    set_mode(\"classification\") \n",
    "\n",
    "SVM_vfold <- vfold_cv(train_data_SVM, v = 5, strata = quality)\n",
    "\n",
    "k_value <- tibble(neighbors = seq(from = 1, to = 100, by = 5))\n",
    "\n",
    "#SVM_results <- workflow() %>% \n",
    "#    add_recipe(SVM_recipe) %>% \n",
    "#    add_model(SVM_model) %>% \n",
    "#    tune_grid(resamples = SVM_vfold, grid = k_value) %>% \n",
    "#    collect_metrics()\n",
    "\n",
    "#k_accuracies <- SVM_results %>% \n",
    "#    filter(.metric == \"accuracy\")\n",
    "\n",
    "#k_accuracies\n",
    "\n",
    "#accuracy_vs_k <- ggplot(k_accuracies, aes(x = neighbors, y = mean)) +\n",
    "#    geom_point() +\n",
    "#    geom_line() +\n",
    "#    labs(x = \"Neighbors\", y = \"Accuracy Estimate\") +\n",
    "#    theme(text = element_text(size = 12))\n",
    "\n",
    "#accuracy_vs_k\n",
    "\n",
    "# from the graph, we select 75 as the k value because it has a relatively high accuracy estimate and is consistent with nearby values\n",
    "\n",
    "best_SVM_model <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 75) %>%\n",
    "    set_engine(\"kknn\") %>%\n",
    "    set_mode(\"classification\")\n",
    "\n",
    "SVM_fit <- workflow() %>%\n",
    "    add_recipe(SVM_recipe) %>%\n",
    "    add_model(best_SVM_model) %>%\n",
    "    fit(data = train_data_SVM)\n",
    "\n",
    "SVM_predictions <- predict(SVM_fit, test_data) %>%\n",
    "    bind_cols(test_data) %>%\n",
    "    metrics(truth = quality, estimate = .pred_class) %>%\n",
    "    filter(.metric == \"accuracy\")\n",
    "SVM_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cortez, P., Cerdeira, A., Almeida, F., Matos, T., Reis, J. (2009). Modeling wine \n",
    "\tpreferences by data mining from physicochemical properties. Decision \n",
    "\tSupport Systems. 47, 547-553. https://doi.org/10.1016/j.dss.2009.05.016.\n",
    " \n",
    "Smith, D. V., & Margolskee, R. F. (2001). Making Sense of Taste. Scientific \n",
    "\tAmerican, 284, 32–39. http://www.jstor.org/stable/26059127\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
